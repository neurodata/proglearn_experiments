{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to try some experiments to assess the baseline performance of single task (city) performance on post COVID data. This gives us an indication on what to improve upon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEP 0 set up train test validation split\n",
    "\n",
    "# STEP 1: understand baseline, single task performance. (probably in another notebook)\n",
    "# Regression on\n",
    "# a) -----\n",
    "# - Weather data\n",
    "# - timestamp (fix the 24 hour thing) [Might remove, or use as the time of day]\n",
    "# - mobility (PC's of the mobility data?) [NEW]\n",
    "# - past values of y [NEW]\n",
    "# - past seasonal values of y [NEW]\n",
    "# - jam into ridge regression and neural network (can be done pretty easily today)\n",
    "# b) ---- harder: past and past seasonal values of e (can be thought about today)\n",
    "# - (optional) holiday?\n",
    "\n",
    "# STEP 2: investigate errors (bias variance)\n",
    "\n",
    "# STEP 3: PL set up\n",
    "# representations from just old data without mobility, increasing modality for forward transfer\n",
    "# same is true for L2N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.utils.validation import check_X_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The city_name field can take on \"Boston\", \"Chicago\", \"Dallas\", \"Houston\", \"Phil\", \"SA\", or \"Seattle\".\n",
    "def load_data(city_name, standardize = False, verbose = False):\n",
    "    df = np.genfromtxt('data/City_Level/%s_mobility_all.csv' % city_name, delimiter=',')\n",
    "    \n",
    "    X_weather = df[:, 1:1+len(weather_col_names)].astype(float)\n",
    "    X_holiday = df[:, 1+len(holiday_col_names)+len(weather_col_names)+len(timestamp_col_names)].astype(float).reshape(-1, 1)\n",
    "    X_mobility = df[:, 1+len(holiday_col_names)+len(weather_col_names)+len(timestamp_col_names):].astype(float)    \n",
    "    X = np.hstack((X_weather, X_holiday, X_mobility))\n",
    "    \n",
    "    if standardize: X = scale(X)\n",
    "    \n",
    "    timestamps = df[:, 1+len(weather_col_names):1+len(weather_col_names)+len(timestamp_col_names)].astype(int)\n",
    "    y = df[:, 0].astype(float)\n",
    "    \n",
    "    metadata = {\"city_name\" : city_name, \n",
    "                \"X_weather\" : X_weather, \n",
    "                \"X_holiday\": X_holiday,\n",
    "                \"X_mobility\" : X_mobility, \n",
    "                \"timestamps\" : timestamps}\n",
    "\n",
    "    if verbose:\n",
    "        print(city_name, \"Energy Consumption Data:\")\n",
    "        print(\"Sample size n =\", X.shape[0])\n",
    "        print(\"Number of weather features d_w =\", X_weather.shape[1])\n",
    "        print(\"Number of holiday features d_h =\", X_holiday.shape[1])\n",
    "        print(\"Number of mobility features d_m =\", X_mobility.shape[1])\n",
    "        print(\"Total number features d =\", X.shape[1])\n",
    "    \n",
    "    return X, y, metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function adds past output values as inputs. 'p' is the number of lagged values to append.\n",
    "# 'ps' is an array of lags. 'scales' is an array which determines the intervals of those lags.\n",
    "def append_past_values(X, y, p_hour, p_day, p_week):\n",
    "    X, y = check_X_y(X, y)\n",
    "    if p_hour == 0 and p_day == 0 and p_week == 0:\n",
    "        return X\n",
    "    \n",
    "    hour_time = 1\n",
    "    day_time = hour_time * 24\n",
    "    week_time = day_time * 7\n",
    "    \n",
    "    ps = np.array([p_hour, p_day, p_week])\n",
    "    times = np.array([hour_time, day_time, week_time])\n",
    "    \n",
    "    burnin = np.max(ps * times)\n",
    "    n_new = n - burnin\n",
    "    X_new = X[burnin:]\n",
    "    \n",
    "    # Make numpy array of indices, and use it to index/map y.\n",
    "    # i is the training example, j is the lag.\n",
    "    for p in range(3):\n",
    "        if ps[p] != 0:\n",
    "            idx = np.fromfunction(lambda i, j: burnin + i - times[p]*(j + 1), (n_new, ps[p]), dtype=int)\n",
    "            X_new = np.hstack((X_new, y[idx]))\n",
    "    \n",
    "    return X_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected X size = (132, 11)\n",
      "Observed X size = (132, 11)\n",
      "Expected X[0] = [0. 0. 167. 166. 165. 144. 120. 0.]\n",
      "Observed X[0] = [  0.   0. 167. 166. 165. 164. 163. 144. 120.  96.   0.]\n"
     ]
    }
   ],
   "source": [
    "# Test append past values.\n",
    "n = 300\n",
    "d = 2\n",
    "\n",
    "X = np.zeros((n, d))\n",
    "y = np.arange(n)\n",
    "\n",
    "p_hour = 5\n",
    "p_day = 3\n",
    "p_week = 1\n",
    "\n",
    "X = append_past_values(X, y, p_hour, p_day, p_week)\n",
    "\n",
    "print(\"Expected X size = (132, 11)\")\n",
    "print(\"Observed X size =\", X.shape)\n",
    "\n",
    "print(\"Expected X[0] = [0. 0. 167. 166. 165. 144. 120. 0.]\")\n",
    "print(\"Observed X[0] =\", X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because the data are time series, this can only be done with one fold.\n",
    "def train_val_test_split(X, y):\n",
    "    X, y = check_X_y(X, y)\n",
    "    \n",
    "    n = len(y)\n",
    "    n_train = int(0.8 * n)\n",
    "    n_val = (n - n_train) // 2\n",
    "    n_test = n - n_train - n_val\n",
    "    \n",
    "    X_train, y_train = X[:n_train], y[:n_train]\n",
    "    X_val, y_val = X[n_train:n_train+n_val], y[n_train:n_train+n_val]\n",
    "    X_test, y_test = X[n_train+n_val:], y[n_train+n_val:]\n",
    "    \n",
    "    return X_train, y_train, X_val, y_val, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected y_test = [45 46 47 48 49]\n",
      "Observed y_test = [45 46 47 48 49]\n"
     ]
    }
   ],
   "source": [
    "# Test append past values.\n",
    "n = 50\n",
    "d = 10\n",
    "X = np.zeros((n, d))\n",
    "y = np.arange(n)\n",
    "\n",
    "X_train, y_train, X_val, y_val, X_test, y_test = train_val_test_split(X, y)\n",
    "\n",
    "print(\"Expected y_test = [45 46 47 48 49]\")\n",
    "print(\"Observed y_test =\", y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate hyper parameters array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute relative error\n",
    "\n",
    "# compute val error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X, y = load_data\n",
    "# hyperparams = generate hyper parameters array\n",
    "# best_hyp = {}\n",
    "# best val_Err = 1\n",
    "\n",
    "# for all hyper params (array of kwargs)\n",
    "#    X, y = append_past_values\n",
    "#    X, y, Xv, yv, Xt, yt = train test split\n",
    "#    compute_val error(X, y )\n",
    "#    if small: update_best\n",
    "\n",
    "# display best"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
