{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from proglearn.voters import TreeClassificationVoter\n",
    "from proglearn.deciders import SimpleAverage\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils import load_embedded_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (10, 5000, 1000)\n",
      "y_train shape: (10, 5000, 1)\n",
      "X_test shape: (10, 1000, 1000)\n",
      "y_test shape: (10, 1000, 1)\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_embedded_data(split_train=True, split_test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lf = pickle.load(open(\"output/lf_task_10.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each task\n",
    "# Check the performance of... \n",
    "\n",
    "# UF (LF with transformer ids = t)\n",
    "# LF (all transformers)\n",
    "# The best out of either of them.\n",
    "# The best out of UF, LF, some random ones with UF and LF in the mix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_transformer_ids(task_id):\n",
    "    transformer_ids = [task_id]\n",
    "    for t in range(10):\n",
    "        if np.random.binomial(1, 0.5) and t != task_id:\n",
    "            transformer_ids.append(t)\n",
    "    return transformer_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_te(task_id, num_candidates = 10, verbose = False):\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Task %d\" % task_id)\n",
    "        print(\"--------------------\")\n",
    "    \n",
    "    train_x = X_train[task_id][0:4500]\n",
    "    train_y = y_train[task_id][0:4500]\n",
    "    \n",
    "    val_x = X_train[task_id][4500:]\n",
    "    val_y = y_train[task_id][4500:]\n",
    "    \n",
    "    test_y = y_test[task_id]\n",
    "    test_x = X_test[task_id]\n",
    "    \n",
    "    # Method 1: UF\n",
    "    if verbose: print(\"Running Method 1: UF...\")\n",
    "    uf_pred = lf.predict(test_x, task_id, transformer_ids = [task_id])\n",
    "    uf_acc = accuracy_score(uf_pred, test_y)\n",
    "    \n",
    "    # Method 2: LF\n",
    "    if verbose: print(\"Running Method 2: LF...\")\n",
    "    lf_pred = lf.predict(test_x, task_id)\n",
    "    lf_acc = accuracy_score(lf_pred, test_y)\n",
    "    \n",
    "    # Method 3: Pick the best on the training set between LF and UF.\n",
    "    if verbose: print(\"Running Method 3: One-vs-All (train)...\")\n",
    "    lf_train_acc = accuracy_score(lf.predict(train_x, task_id), train_y)\n",
    "    uf_train_acc = accuracy_score(lf.predict(train_x, task_id, transformer_ids = [task_id]), train_y)\n",
    "    if uf_train_acc > lf_train_acc:\n",
    "        ova_train_acc = uf_acc\n",
    "        ova_train_transformers = [task_id]\n",
    "    else:\n",
    "        ova_train_acc = lf_acc\n",
    "        ova_train_transformers = np.arange(10)\n",
    "    \n",
    "    \n",
    "    # Method 4: Pick the best on validation set between UF and LF.\n",
    "    if verbose: print(\"Running Method 4: One-vs-All (val)...\")\n",
    "    lf_val_acc = accuracy_score(lf.predict(val_x, task_id), val_y)\n",
    "    uf_val_acc = accuracy_score(lf.predict(val_x, task_id, transformer_ids = [task_id]), val_y)\n",
    "    if uf_val_acc > lf_val_acc:\n",
    "        ova_val_acc = uf_acc\n",
    "        ova_val_transformers = [task_id]\n",
    "    else:\n",
    "        ova_val_acc = lf_acc\n",
    "        ova_val_transformers = np.arange(10)\n",
    "    \n",
    "    \n",
    "    # Method 5: Sample the best transformers based on the training set.\n",
    "    if verbose: print(\"Running Method 5: Sample (train)...\")\n",
    "    best_acc = ova_train_acc\n",
    "    best_transformer_ids = ova_train_transformers\n",
    "    for c in range(num_candidates):\n",
    "        transformer_ids = sample_transformer_ids(task_id)\n",
    "        acc = accuracy_score(lf.predict(train_x, task_id, transformer_ids = transformer_ids), train_y)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_transformer_ids = transformer_ids\n",
    "    sample_train_acc = accuracy_score(lf.predict(test_x, task_id, transformer_ids = best_transformer_ids), test_y)\n",
    "    sample_train_transformed_ids = best_transformer_ids\n",
    "            \n",
    "    \n",
    "    # Methpd 6: Sample the best transformers based on the validation set.\n",
    "    if verbose: print(\"Running Method 6: Sample (val)...\")\n",
    "    best_acc = ova_val_acc\n",
    "    best_transformer_ids = ova_val_transformers\n",
    "    for c in range(num_candidates):\n",
    "        transformer_ids = sample_transformer_ids(task_id)\n",
    "        acc = accuracy_score(lf.predict(val_x, task_id, transformer_ids = transformer_ids), val_y)\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_transformer_ids = transformer_ids\n",
    "    sample_val_acc = accuracy_score(lf.predict(test_x, task_id, transformer_ids = best_transformer_ids), test_y)\n",
    "    sample_val_transformed_ids = best_transformer_ids\n",
    "    \n",
    "    results = {\n",
    "        'lf_te' : (1 - uf_acc) / (1 - lf_acc),\n",
    "        'ova_train_te' : (1 - uf_acc) / (1 - ova_train_acc),\n",
    "        'ova_val_te' : (1 - uf_acc) / (1 - ova_val_acc),\n",
    "        'sample_train_te' : (1 - uf_acc) / (1 - sample_train_acc),\n",
    "        'sample_val_te' : (1 - uf_acc) / (1 - sample_val_acc)\n",
    "    }\n",
    "    \n",
    "    pickle.dump(results, open(\"output/robust_result_%d.p\" % task_id, \"wb\"))\n",
    "    \n",
    "    print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_te(ax, task_id):\n",
    "    \n",
    "    results = pickle.load(open(\"output/robust_result_%d.p\" % task_id, \"rb\"))\n",
    "    \n",
    "    x = 0.3 * np.arange(5)\n",
    "    width = 0.2\n",
    "\n",
    "    ax.bar(x[0], results['lf_te'], width=width, color='#d7191c', align='center', label = 'LF')\n",
    "    ax.bar(x[1], results['ova_train_te'], width=width, color='#fdae61', align='center', label = 'OvA Train')\n",
    "    ax.bar(x[2], results['ova_val_te'], width=width, color='#ffffbf', align='center', label = 'OvA Val')\n",
    "    ax.bar(x[3], results['sample_train_te'], width=width, color='#abd9e9', align='center', label = 'Sample Train')\n",
    "    ax.bar(x[4], results['sample_val_te'], width=width, color='#2c7bb6', align='center', label = 'Sample Val')\n",
    "    \n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    # ax.set_xticklabels([])\n",
    "    \n",
    "    ax.set_xlabel(\"Task %d\" % task_id)\n",
    "    # ax.set_ylabel(\"Transfer Efficiency\")\n",
    "    ax.set_ylim(0.5, 1.5)\n",
    "    \n",
    "    ax.axhline(y=1, color = 'k')\n",
    "\n",
    "    # ax.set_title(\"L2F+ResNet50 Encoded Split-CIFAR, n_trees=300, n_train=5000\")\n",
    "    # plt.savefig(\"te_fig.pdf\", bbox_inches = \"tight\")\n",
    "    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 0\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.7791411042944784, 'ova_train_te': 0.7791411042944784, 'ova_val_te': 1.0, 'sample_train_te': 1.007936507936508, 'sample_val_te': 0.888111888111888}\n",
      "Task 1\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 1.0056818181818181, 'ova_train_te': 1.0, 'ova_val_te': 1.0056818181818181, 'sample_train_te': 1.1062500000000002, 'sample_val_te': 1.023121387283237}\n",
      "Task 2\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.9364161849710982, 'ova_train_te': 0.9364161849710982, 'ova_val_te': 1.0, 'sample_train_te': 1.0945945945945947, 'sample_val_te': 1.0657894736842106}\n",
      "Task 3\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.9731182795698925, 'ova_train_te': 1.0, 'ova_val_te': 1.0, 'sample_train_te': 1.0402298850574714, 'sample_val_te': 1.0838323353293413}\n",
      "Task 4\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.8715083798882681, 'ova_train_te': 1.0, 'ova_val_te': 0.8715083798882681, 'sample_train_te': 0.9873417721518988, 'sample_val_te': 0.923076923076923}\n"
     ]
    }
   ],
   "source": [
    "for t in [0, 1, 2, 3, 4]:\n",
    "    get_te(t, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task 5\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.844621513944223, 'ova_train_te': 1.0, 'ova_val_te': 1.0, 'sample_train_te': 0.9257641921397379, 'sample_val_te': 1.0}\n",
      "Task 6\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.9330543933054393, 'ova_train_te': 1.0, 'ova_val_te': 1.0, 'sample_train_te': 0.9570815450643776, 'sample_val_te': 1.009049773755656}\n",
      "Task 7\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.9216589861751151, 'ova_train_te': 0.9216589861751151, 'ova_val_te': 1.0, 'sample_train_te': 0.9950248756218906, 'sample_val_te': 1.0}\n",
      "Task 8\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n",
      "Running Method 6: Sample (val)...\n",
      "{'lf_te': 0.8571428571428571, 'ova_train_te': 1.0, 'ova_val_te': 1.0, 'sample_train_te': 0.9017341040462427, 'sample_val_te': 1.0}\n",
      "Task 9\n",
      "--------------------\n",
      "Running Method 1: UF...\n",
      "Running Method 2: LF...\n",
      "Running Method 3: One-vs-All (train)...\n",
      "Running Method 4: One-vs-All (val)...\n",
      "Running Method 5: Sample (train)...\n"
     ]
    }
   ],
   "source": [
    "for t in [5, 6, 7, 8, 9]:\n",
    "    get_te(t, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_figure():\n",
    "    sns.set(font_scale = 1)\n",
    "    sns.set_style(\"ticks\")\n",
    "    plt.rcParams[\"font.family\"] = \"sans-serif\"\n",
    "    plt.rcParams['figure.figsize'] = [12, 5] # TODO: Tune\n",
    "    fig, axes = plt.subplots(2, 5)\n",
    "    \n",
    "    for t in range(5):\n",
    "        plot_te(axes[0, t], t)\n",
    "        plot_te(axes[1, t], t + 5)\n",
    "    \n",
    "    # axes[1, 0].legend(loc = \"lower left\")\n",
    "    axes[0, 4].legend(bbox_to_anchor=(1, 1))\n",
    "    \n",
    "    axes[0, 0].set_ylabel('Transfer Efficiency')\n",
    "    axes[1, 0].set_ylabel('Transfer Efficiency')\n",
    "    axes[0, 0].set_yticks([0.5, 1, 1.5])\n",
    "    axes[1, 0].set_yticks([0.5, 1, 1.5])\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(\"robust_fig.pdf\", bbox_inches = \"tight\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
