{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from utils import load_imdb, load_yelp, load_amazon\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get p(y | x, t). This should be (n * 6) array, with n = the number of test examples from toxic comment classification.\n",
    "y_test_toxic = pickle.load(open(\"output/y_test.p\", \"rb\"))\n",
    "task_cond_probs = pickle.load(open(\"output/probs.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_test shape:  (63978, 6)\n",
      "task_cond_probs shape:  (63978, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"y_test shape: \", y_test_toxic.shape)\n",
    "print(\"task_cond_probs shape: \", task_cond_probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0.]]\n",
      "[1 1 1 1 1 1 1 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Convert y_test to be binary, where any label is considered 'toxic' = 0 = negative, and no labels = 'non-toxic' positive.\n",
    "y_test_bin = (y_test_toxic.sum(axis = 1) == 0).astype(int)\n",
    "\n",
    "print(y_test_toxic[0:10])\n",
    "print(y_test_bin[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get p(t | x), probability of each task. This should be This should be (n * 3) array, with \n",
    "# n = the number of test examples from toxic comment classification.\n",
    "n_estimators = 35\n",
    "\n",
    "task_prior_probs_target = pickle.load(open(\"output/task_prior_probs_target_%d.p\" % 10, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "task_prior_probs_target shape: (63978, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"task_prior_probs_target shape:\", task_prior_probs_target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "source task priors shape:  (343000, 3)\n",
      "source task labels shape:  (343000,)\n",
      "[[0.69515271 0.05152521 0.25332209]\n",
      " [0.94367129 0.02546505 0.03086366]\n",
      " [0.94367129 0.02546505 0.03086366]\n",
      " [0.94367129 0.02546505 0.03086366]\n",
      " [0.94367129 0.02546505 0.03086366]\n",
      " [0.87360956 0.08456998 0.04182045]\n",
      " [0.93478971 0.02349136 0.04171893]\n",
      " [0.87360956 0.08456998 0.04182045]\n",
      " [0.72259415 0.17597701 0.10142884]\n",
      " [0.79697351 0.11859914 0.08442735]]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Check that this can actually discriminate the class well for the source data.\n",
    "task_prior_probs_source = pickle.load(open(\"output/task_prior_probs_source_%d.p\" % 10, \"rb\"))\n",
    "source_task_labels = pickle.load(open(\"output/source_task_labels.p\", \"rb\"))\n",
    "\n",
    "print(\"source task priors shape: \", task_prior_probs_source.shape)\n",
    "print(\"source task labels shape: \", source_task_labels.shape)\n",
    "\n",
    "print(task_prior_probs_source[0:10])\n",
    "print(source_task_labels[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source task prediction accuracy:  0.9280991253644315\n"
     ]
    }
   ],
   "source": [
    "predicted_source_task_labels = np.argmax(task_prior_probs_source, axis = 1)\n",
    "\n",
    "acc = accuracy_score(predicted_source_task_labels, source_task_labels)\n",
    "print(\"Source task prediction accuracy: \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X_train' and 'X_test' are each a list of string-valued reviews of movies.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 45\n",
      "Number of testing examples = 5000\n",
      "First few examples:\n",
      "Review: -------------------------------------------------------\n",
      "<br /><br />Once I ignored some of the implausibilities, this was actually a fairly decent horror/monster flick. So, I'll give some of the good points first: - the dragon was quite convincing, especially as she prowled through the tunnels looking for lunch (hint: she likes humans). - the action was fairly non stop, and, after a weak beginning, I got quite absorbed in the storyline. - sorry to say, I was kind of rooting for the dragon - she was probably the most convincing and consistent character in the movie.<br /><br />Now for the implausible stuff **maybe some spoilers**: - if you were hunting a fire-breathing dragon in 1100 AD, would you charge into its cave with a barrel of gunpowder under your arm? Duh. - a female character with an all-American name, blonde hair and obvious Slavic accent, trying to pretend she's Spanish? Huh? - a lead scientist whose Slavic accent you can cut with a knife, and he's supposedly born in Chicago, educated in USA? - a military helicopter pilot who does his own repairs, flies a huge transport copter with no other crew, and is an expert marksman and combat soldier to boot? OK. Uh huh. I won't even mention his giving 3 different call signs in 2 minutes while communicating with his base.<br /><br />It's still better than some of the Japanese monster flicks from the 60's, but not by much. If we're lucky, we won't see Dragon Fighter 2, though naturally the ending left that possibility wide open. Or, maybe, they'll hire a real director next time.<br /><br />In spite of everything, I gave this flick a 4 out of 10. Add 2 more if they rewrite the plot, and Dean Cain gets eaten in the first ten minutes. <grin>\n",
      "Sentiment: ----------------------------------------------------\n",
      "0\n",
      "Review: -------------------------------------------------------\n",
      "Boston legal has turned its tail and is headed for the barn door and th pig slop it has created! When this show first aired almost four season back it was a humorous slap at the legal system which all actors seem to take pride in portraying. It was funny, diversified, and to some extent factual. The characters portrayed were acceptable and to an extent real in their portrayals. The sexual comment and activity were limited and humorous. Julie Bowen is and was beautiful as in other series she participated but is now dragged to the lower depths of Media programming of sex and violence. Julie is an excellent actress and needs a more stable platform than this \"production\". Rene Adjurdubois Is an excellent actor who has from the days of \"Benson\" to this production held his own in the field of entertainment, always showing the humor and respectful acting of the production. Captain Kirk \"is\". Funny and humorous is Candace Bergan and is to be admired for her continuing in this production and is a good actress. James Spader, there is no doubt in his acting ability, however he should go back to his XXX origins such as \"Crash\" as it appears he has much talent and inclination in that direction. We ask that this series be trashed as it already is and its really starting to smell!!!\n",
      "Sentiment: ----------------------------------------------------\n",
      "0\n",
      "Review: -------------------------------------------------------\n",
      "I bought this DVD after seeing it highly ranked here. It's just a short 20 minutes zombie film. Nothing special about it except for the music perhaps.<br /><br />Don't buy it! Not even really worth spending 20 minutes to see it. Only if you're really bored...\n",
      "Sentiment: ----------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "# Check that for the source tasks, 0 corresponds to negative and 1 corresponds to positive.\n",
    "X_train, y_train, X_test, y_test = load_imdb(view=\"raw\", verbose=True, subsample_frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X_train' and 'X_test' are each a list of string-valued reviews of business.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 560\n",
      "Number of testing examples = 38000\n",
      "First few examples:\n",
      "Review: -------------------------------------------------------\n",
      "This place is one of my favorite comic shops. I actually live closer to a different one, but I drive to chandler just to go to this one. I like their selection and when they have the dollar sale you can get some ridiculous deals. The staff is ridiculously friendly and I usually always walk out with whatever I wanted. They also have some cool events from time to time and i've found their prices to be reasonable and comparable to other comic shops.\n",
      "Sentiment: ----------------------------------------------------\n",
      "1\n",
      "Review: -------------------------------------------------------\n",
      "The wait time for an appointment is ridiculous. Been waiting over an hour and a half for my scheduled appointment time. These people do not value patients time\n",
      "Sentiment: ----------------------------------------------------\n",
      "0\n",
      "Review: -------------------------------------------------------\n",
      "I did not like this hotel at all. It's very old and not comforts in it. \\nThe good thing is that it was cheap but at the time was like a room just to sleep! \\nThere is no view at all and while you are in the Vegas it should not be those kind of rooms. \\nWhen we came in to the room we just sow a trash cans and an a conditioner staff...!!!\\nBut the Casino and staff were good and cute  ...it's was almost like we were in the animation movies...but inside the casino...\n",
      "Sentiment: ----------------------------------------------------\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_yelp(view=\"raw\", verbose=True, subsample_frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'X_train' and 'X_test' are each \n",
      "                a list of string-valued reviews of products.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, \n",
      "                where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 3600\n",
      "Number of testing examples = 400000\n",
      "First few examples:\n",
      "Review: -------------------------------------------------------\n",
      "Expensive Junk\n",
      "Sentiment: ----------------------------------------------------\n",
      "0.0\n",
      "Review: -------------------------------------------------------\n",
      "Toast too dark\n",
      "Sentiment: ----------------------------------------------------\n",
      "0.0\n",
      "Review: -------------------------------------------------------\n",
      "Excellent imagery...dumbed down story\n",
      "Sentiment: ----------------------------------------------------\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = load_amazon(view=\"raw\", verbose=True, subsample_frac=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce toxic comment predictions.\n",
    "# task_prior_probs_target = [n*3]\n",
    "# task_cond_probs [n*6]\n",
    "# y_test_bin [n*1]\n",
    "\n",
    "task_0_class_0 = task_cond_probs[:, 0] * task_prior_probs_target[:, 0]\n",
    "task_0_class_1 = task_cond_probs[:, 1] * task_prior_probs_target[:, 0]\n",
    "task_1_class_0 = task_cond_probs[:, 2] * task_prior_probs_target[:, 1]\n",
    "task_1_class_1 = task_cond_probs[:, 3] * task_prior_probs_target[:, 1]\n",
    "task_2_class_0 = task_cond_probs[:, 4] * task_prior_probs_target[:, 2]\n",
    "task_2_class_1 = task_cond_probs[:, 5] * task_prior_probs_target[:, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "class_0 = task_0_class_0 + task_1_class_0 + task_2_class_0\n",
    "class_1 = task_0_class_1 + task_1_class_1 + task_2_class_1\n",
    "\n",
    "# Should add up to 1.\n",
    "print((class_0 + class_1)[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.13      0.83      0.22      6243\n",
      "           1       0.96      0.39      0.55     57735\n",
      "\n",
      "    accuracy                           0.43     63978\n",
      "   macro avg       0.54      0.61      0.39     63978\n",
      "weighted avg       0.87      0.43      0.52     63978\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = (class_1 > 0.5).astype(int)\n",
    "\n",
    "report = classification_report(y_test_bin, y_pred)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chance:  0.90241958173122\n"
     ]
    }
   ],
   "source": [
    "# Chance:\n",
    "print(\"Chance: \", y_test_bin.sum() / len(y_test_bin))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
