{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook chooses the sample sizes for the source tasks (Amazon, Yelp, IMDB) that achieve 'good' performance on the classification tasks. This sample size is chosen for the pregressive learning experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import copy\n",
    "\n",
    "from utils import load_imdb, load_yelp, load_toxic_comment, load_amazon\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from proglearn.forest import UncertaintyForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experimental parameters\n",
    "n_estimators = 10\n",
    "verbose = True\n",
    "subsample_fracs = [0.001, 0.003, 0.01, 0.03, 0.1, 0.3, 1]\n",
    "# subsample_fracs = [0.001, 0.003] # for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_tasks = [\n",
    "    {\n",
    "        'name' : 'Yelp Review Sentiment Analysis',\n",
    "        'filename' : 'yelp',\n",
    "        'load' : load_yelp,\n",
    "    },\n",
    "    {\n",
    "        'name' : 'IMDB Review Sentiment Analysis',\n",
    "        'filename' : 'imdb',\n",
    "        'load' : load_imdb,\n",
    "        'task_id' : 1,\n",
    "    },\n",
    "    {\n",
    "        'name' : 'Amazon Review Sentiment Analysis',\n",
    "        'filename' : 'amazon',\n",
    "        'load' : load_amazon,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TASK: Yelp Review Sentiment Analysis\n",
      "'X_train' and 'X_test' are each an n-by-d array of BERT embedded reviews of a business.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 560000\n",
      "Input dimension d = 512\n",
      "Number of testing examples = 38000\n",
      "TASK: IMDB Review Sentiment Analysis\n",
      "'X_train' and 'X_test' are each an n-by-d array of BERT embedded movie reviews.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 45000\n",
      "Input dimension d = 512\n",
      "Number of testing examples = 5000\n",
      "TASK: Amazon Review Sentiment Analysis\n",
      "'X_train' and 'X_test' are each an \n",
      "                n-by-d array of BERT embedded product reviews.\n",
      "'y_train' and 'y_test' are each list of binary sentiments, \n",
      "                where 0 = 'negative' and 1 = 'positive'.\n",
      "Number of training examples = 300000\n",
      "Input dimension d = 512\n",
      "Number of testing examples = 300000\n"
     ]
    }
   ],
   "source": [
    "for task in source_tasks:\n",
    "    print(\"TASK:\", task['name'])    \n",
    "    print(\"----------------------------\")\n",
    "    X_train_full, y_train_full, X_test, y_test = task['load'](verbose = verbose)\n",
    "    \n",
    "    accs = np.zeros(len(subsample_fracs))\n",
    "    for i, subsample_frac in enumerate(subsample_fracs):\n",
    "        _, X_train, _, y_train = train_test_split(X_train_full, y_train_full, test_size=subsample_frac)\n",
    "        uf = UncertaintyForest(n_estimators=n_estimators)\n",
    "        uf.fit(X_train, y_train)\n",
    "        \n",
    "        accs[i] = accuracy_score(uf.predict(X_test), y_test)\n",
    "    \n",
    "    pickle.dump(accs, open(\"output/uf_accs_%s_%d.p\" % (task['filename'], n_estimators), \"wb\"))\n",
    "pickle.dump(subsample_fracs, open(\"output/uf_subsample_fracs.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
